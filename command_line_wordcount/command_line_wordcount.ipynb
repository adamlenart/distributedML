{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command line wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount using a single thread  \n",
    "\n",
    "Write a program called alice_words.py that creates a text file named __alice_words.txt__ containing an alphabetical tab separated listing of all the words, and the number of times each occurs, in the text version of Alice’s Adventures in Wonderland. (http://www.gutenberg.org/cache/epub/11/pg11.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  169k  100  169k    0     0   133k      0  0:00:01  0:00:01 --:--:--  149k\n"
     ]
    }
   ],
   "source": [
    "# !curl 'http://www.gutenberg.org/cache/epub/11/pg11.txt' -o alicesTExtFilename.txt\n",
    "# sometimes the above link produces junk characters. However, the direct link works as expected:\n",
    "!curl 'http://www.gutenberg.org/files/11/11-0.txt' -o alicesTextFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿Project Gutenberg’s Alice’s Adventures in Wonderland, by Lewis Carroll\r",
      "\r\n",
      "\r",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r",
      "\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r",
      "\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r",
      "\r\n",
      "with this eBook or online at www.gutenberg.org\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "Title: Alice’s Adventures in Wonderland\r",
      "\r\n",
      "\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#display the first few lines\n",
    "!head alicesTextFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting alice_words.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile alice_words.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "pathToFile = sys.argv[1]\n",
    "wordCounts = defaultdict(int)\n",
    "wordList = []\n",
    "\n",
    "def wordcount(pathToFile):\n",
    "    # takes the path to the file as command line argument\n",
    "    # prints sorted tab separated list of words and counts\n",
    "    # ex) print word,'\\t',count\n",
    "    # returns sorted list of tuples of words and counts: wordList\n",
    "    # ex) wordList = [('a', 690),('abide', 2),...]\n",
    "  \n",
    "    with open (pathToFile, \"r\") as my_text:\n",
    "        # read the whole text file\n",
    "        text = my_text.read()\n",
    "        # count word frequencies\n",
    "        for word in re.findall(r'[a-z]+', text.lower()):\n",
    "            wordCounts[word] += 1\n",
    "            \n",
    "    # extract counts and print to tab-separated text\n",
    "    for word in sorted(wordCounts):\n",
    "        count = wordCounts[word]\n",
    "        print word,'\\t',count\n",
    "        # save the word frequencies for the return statement\n",
    "        wordList.append((word, count))\n",
    "    \n",
    "  \n",
    "    return wordList\n",
    "\n",
    "wordcount(pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python alice_words.py 'alicesTextFilename.txt' > alice_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty print top 10 results from alice_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           Count\n",
      "====================\n",
      "a                690\n",
      "abide              2\n",
      "able               1\n",
      "about            102\n",
      "above              3\n",
      "absence            1\n",
      "absurd             2\n",
      "accept             1\n",
      "acceptance         1\n",
      "accepted           2\n"
     ]
    }
   ],
   "source": [
    "def top_n_printer(text,n):\n",
    "    print '{:15}{}'.format('Word', 'Count')\n",
    "    print '='*20\n",
    "\n",
    "    with open(text) as f:\n",
    "        idx = 0\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            word, count = line.split('\\t')\n",
    "        # print the top n lines\n",
    "            if idx < n:\n",
    "                print '{:17}{:3d}'.format(word, int(count))\n",
    "            idx += 1  \n",
    "    \n",
    "top_n_printer(\"alice_words.txt\",10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times does the word alice occur in the book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw111.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile return_word.py\n",
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "\n",
    "word = sys.argv[1]\n",
    "pathToFile = sys.argv[2]\n",
    "\n",
    "def return_word(word,pathToFile):\n",
    "  # takes a word and the path to the file as arguments\n",
    "  # returns the line containing the word and count\n",
    "    \n",
    "  # START STUDENT CODE HW111\n",
    "    args = ['grep','-i', word, pathToFile]\n",
    "    out, err = subprocess.Popen(args,stdout=subprocess.PIPE).communicate()\n",
    "    return(out)\n",
    "  # END STUDENT CODE HW111\n",
    "    \n",
    "print return_word(word,pathToFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice \t403\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python return_word.py 'alice' 'alice_words.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Command Line Map Reduce Framework  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pWordCount.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile pWordCount.sh\n",
    "#!/bin/bash\n",
    "## pWordCount.sh\n",
    "## Author: James G. Shanahan\n",
    "## Usage: pWordCount.sh m wordlist testFile.txt\n",
    "## Input:\n",
    "##       m = number of processes (maps), e.g., 4\n",
    "##       word = a word in quotes, e.g., \"alice\"\n",
    "##       inputFile = a text input file\n",
    "##\n",
    "## Instructions: Read this script and its comments closely.\n",
    "##               Do your best to understand the purpose of each command,\n",
    "##               and focus on how arguments are supplied to mapper.py/reducer.py,\n",
    "##               as this will determine how the python scripts take input.\n",
    "\n",
    "\n",
    "\n",
    "usage()\n",
    "{\n",
    "    echo ERROR: No arguments supplied\n",
    "    echo\n",
    "    echo To run use\n",
    "    echo \"pWordCount.sh m word inputFile\"\n",
    "    echo Input:\n",
    "    echo \"number of processes/maps, EG, 4\"\n",
    "    echo \"word = a word in quotes, e.g., 'alice'\"\n",
    "    echo \"inputFile = a text input file\"\n",
    "}\n",
    "\n",
    "if [ $# -eq 0 ]\n",
    "  then\n",
    "    usage  \n",
    "    exit 1\n",
    "fi\n",
    "    \n",
    "## collect user input\n",
    "m=$1 ## the number of parallel processes (maps) to run\n",
    "\n",
    "word=$2 ## if set to \"*\", then all words are used\n",
    "\n",
    "## a text file \n",
    "data=$3\n",
    "\n",
    "## 'wc' determines the number of lines in the data\n",
    "## 'perl -pe' regex strips the piped wc output to a number\n",
    "linesindata=`wc -l $data | perl -pe 's/^.*?(\\d+).*?$/$1/'`\n",
    "\n",
    "## determine the lines per chunk for the desired number of processes\n",
    "linesinchunk=`echo \"$linesindata/$m+1\" | bc`\n",
    "\n",
    "## split the original file into chunks by line\n",
    "split -l $linesinchunk $data $data.chunk.\n",
    "\n",
    "## assign python mappers (mapper.py) to the chunks of data\n",
    "## and emit their output to temporary files\n",
    "for datachunk in $data.chunk.*; do\n",
    "    ## feed word list to the python mapper here and redirect STDOUT to a temporary file on disk\n",
    "    ####\n",
    "    ####\n",
    "    ./mapper.py  \"$word\" < $datachunk > $datachunk.counts &\n",
    "    ####\n",
    "    ####\n",
    "done\n",
    "## wait for the mappers to finish their work\n",
    "wait\n",
    "    \n",
    "###----------------------------------------------------------------------------------------\n",
    "#TODO \n",
    "#Insert a sort -k1,1 above to collate wordCount records with the same key (i.e., same word)\n",
    "\n",
    "for wordcount in $data.chunk.*.counts; do    \n",
    "    sort -k1,1 $wordcount > $wordcount.sorted\n",
    "done    \n",
    "    \n",
    "#\n",
    "###----------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "## 'ls' makes a list of the temporary count files\n",
    "## 'perl -pe' regex replaces line breaks with spaces\n",
    "countfiles=`\\ls $data.chunk.*.sorted | perl -pe 's/\\n/ /'`\n",
    "## feed the list of countfiles to the python reducer and redirect STDOUT to disk\n",
    "####\n",
    "####\n",
    "cat $countfiles | ./reducer.py  > $data.output\n",
    "####\n",
    "####\n",
    "\n",
    "## clean up the data chunks and temporary count files\n",
    "\\rm $data.chunk.*\n",
    "    \n",
    "## display the content of the output file:\n",
    "cat $data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "## pWordCount.sh\r\n",
      "## Author: James G. Shanahan\r\n",
      "## Usage: pWordCount.sh m wordlist testFile.txt\r\n",
      "## Input:\r\n",
      "##       m = number of processes (maps), e.g., 4\r\n",
      "##       word = a word in quotes, e.g., \"alice\"\r\n",
      "##       inputFile = a text input file\r\n",
      "##\r\n",
      "## Instructions: Read this script and its comments closely.\r\n"
     ]
    }
   ],
   "source": [
    "!head pWordCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the execution priviledges to make the shell script executable by all\n",
    "!chmod a+x pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the framework without parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No arguments supplied\r\n",
      "\r\n",
      "To run use\r\n",
      "pWordCount.sh m word inputFile\r\n",
      "Input:\r\n",
      "number of processes/maps, EG, 4\r\n",
      "word = a word in quotes, e.g., 'alice'\r\n",
      "inputFile = a text input file\r\n"
     ]
    }
   ],
   "source": [
    "! ./pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following two cells to generate mapper and reducer files, then run the shell script again with arguments.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "findword = sys.argv[1]\n",
    "for line in sys.stdin:\n",
    "    # count all occurances of the word in each line:\n",
    "    count = count + line.lower().count(findword)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## Description: reducer code for HW1.2\n",
    "import sys\n",
    "import re\n",
    "total = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    total += int(line)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the files executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x mapper.py\n",
    "!chmod a+x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the framework with parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\r\n"
     ]
    }
   ],
   "source": [
    "!./pWordCount.sh 4 'alice' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount via Command Line Map Reduce Framework \n",
    "\n",
    "* mapper.py counts all occurrences of a single word.\n",
    "* reducer.py sums the count value from the collated records for each  word.\n",
    "* pWordCount.sh, runs mapper.py and reducer.py and sorts the key-value pair records by key from the mappers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, mapper.py will read in a portion (i.e., a single record corresponding to a row) of the Alice in Wonderland data,\n",
    "count the number of occurences of the  word in question and print/emit a count to the output stream. The reducer responsible for reading in counts of the word from the input stream, and summarizing them before printing that summary to the output stream.\n",
    "See example the [notebook](http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/5zq0faibmvtjlbr/DivideAndConquer2-python-Plus-CmdLine.ipynb)\n",
    "See video section 1.12.1 1.12.1 Poor Man's MapReduce Using Command Line (Part 2) located at: \n",
    "https://learn.datascience.berkeley.edu/mod/page/view.php?id=10961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW12MAPPER\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import repeat\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# --------------------- function definitions --------------------------- #\n",
    "\n",
    "def dictionary_builder(text,findword):\n",
    "    '''Build a default dictionary of words and corresponding counts.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text: a text file object\n",
    "    findword: a string, if it is '*', the function looks for all of the words in text\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    A defaultdict with words as keys and counts as items.\n",
    "    '''\n",
    "    wordCounts = defaultdict(int)\n",
    "    \n",
    "    # define regular expression to look for\n",
    "    if findword == '*':\n",
    "        word = re.compile(r'[a-z]+',re.IGNORECASE)\n",
    "    else:\n",
    "        word = re.compile(r'(?<![\\w]){0}(?![\\w])'.format(findword),re.IGNORECASE)\n",
    "    \n",
    "    # count word frequencies for each line in text\n",
    "    for line in text.readlines():\n",
    "        for this_word in word.findall(line):\n",
    "            wordCounts[this_word] += 1\n",
    "    return wordCounts\n",
    "    \n",
    "def word_emitter(word):\n",
    "    '''Prints word from a wordCounts dictionary to stdout'''\n",
    "    print word,'\\t',wordCounts[word]\n",
    "\n",
    "# ---------------------- run -------------------- #    \n",
    "    \n",
    "findword = sys.argv[1]\n",
    "# construct word count dictionary\n",
    "wordCounts = dictionary_builder(sys.stdin,findword)\n",
    "# emit the words and counts to stdout\n",
    "map(word_emitter,wordCounts.keys())\n",
    "    \n",
    "# END STUDENT CODE HW12MAPPER    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW12REDUCER\n",
    "import sys\n",
    "\n",
    "this_word = None\n",
    "word = None\n",
    "total = 0\n",
    "for word_count in sys.stdin:\n",
    "    word, count = word_count.split('\\t')\n",
    "    # cast count to integer from string\n",
    "    count = int(count)\n",
    "    # turn all words lowercase for summing them up\n",
    "    word = word.lower()\n",
    "    \n",
    "    # if the current word is the same as the previous one, sum them up (that is, sum up the lower and upper case instances)\n",
    "    if this_word == word:\n",
    "        total += count    \n",
    "    # if the two adjacent words are different     \n",
    "    else:\n",
    "        if this_word is not None:\n",
    "            # print all words to stdout\n",
    "            print '{0}\\t{1}'.format(this_word, total)   \n",
    "        total = count\n",
    "        this_word = word\n",
    "\n",
    "# print to stdout output when the input argument is a single word \n",
    "print '{0}\\t{1}'.format(this_word, total)\n",
    "# END STUDENT CODE HW12REDUCER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell use the Unix chmod command to change the permissions of the mapper/reducer using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x mapper.py; \n",
    "!chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the command below with 1 mapper. You should get the same result as before, with more than 1 mappers, a different one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice \t403\r\n"
     ]
    }
   ],
   "source": [
    "!./pWordCount.sh 1 \"alice\" 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!./pWordCount.sh 1 \"*\" 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           Count\n",
      "====================\n",
      "a                690\n",
      "abide              2\n",
      "able               1\n",
      "about            102\n",
      "above              3\n",
      "absence            1\n",
      "absurd             2\n",
      "accept             1\n",
      "acceptance         1\n",
      "accepted           2\n"
     ]
    }
   ],
   "source": [
    "top_n_printer('alicesTExtFilename.txt.output',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!./pWordCount.sh 2 \"*\" 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           Count\n",
      "====================\n",
      "a                391\n",
      "abide              1\n",
      "able               1\n",
      "about             49\n",
      "above              2\n",
      "absurd             2\n",
      "acceptance         1\n",
      "accounts           1\n",
      "accustomed         1\n",
      "across             2\n"
     ]
    }
   ],
   "source": [
    "top_n_printer('alicesTExtFilename.txt.output',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of mappers is higher than one and the word counter script takes only a single word as argument, the script returns the same results as with only one mapper because all of the temporary results contain only row with the partial sum which can be added together. \n",
    "\n",
    "However, when the number of mappers is higher than one and the word counter script takes all of the words as argument, the script emits the partial results sorted within each temporary file that the mappers produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Count words staring with uppercase and words starting with lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "\n",
    "word_list = []\n",
    "total = 0\n",
    "upper_sum = 0\n",
    "for word_count in sys.stdin:\n",
    "    word, count = word_count.split('\\t')\n",
    "    if word[0].isupper():\n",
    "        upper_sum += int(count)\n",
    "    total += int(count)\n",
    "\n",
    "print 'Number of words starting with\\n\\n\\tlowercase letters: {lower}\\n\\tuppercase letters: {upper}'.format(lower=total-upper_sum,upper=upper_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!./pWordCount.sh 1 \"*\" 'alicesTExtFilename.txt'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
